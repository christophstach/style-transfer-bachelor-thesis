\chapter{Fazit}

Dieses Kapitel beinhaltet eine kurze Zusammenfassung der Abschlussarbeit. Das Thema wird kritisch betrachtet und es wird auf mögliche Probleme eingegangen. Letztlich wird ein Ausblick über zukünftige Entwicklungen und Möglichkeiten gegeben.

\section{Zusammenfassung}

In der Abschlussarbeit wurde sich intensiv mit Style Transfer Algorithmen beschäftigt und diese auf Geräten mit leistungsarmer Hardware getestet. Anfangs wurde die Theorie zu Neuronalen Netzwerken und Style Transfer analysiert. Es wurde eine Implementierung geplant und abschließend mit dem Framework PyTorch umgesetzt. Unterschiedliche Netzwerke wurden erfolgreich trainiert und Stile extrahiert. Verschiedene Hyperparametereinstellungen wurden getestet und die Performanz der Netzwerke gemessen.


\section{Kritischer Rückblick}

Besonders das Training und das Durchführen der Experimente muss kritisch betrachtet werden. Es wurden die entsprechenden Hyperparametereinstellungen ausführlich nur mit zwei Gemälden getestet. Fraglich ist ob diese den gleichen Effekt bei anderen Gemälden erzielen. Deswegen wird davon ausgegangen, dass für jeden Stil die Hyperparametereinstellungen individuell getestet werden müssen.

Bei den gewählten Gemälden waren alle Netzwerkarchitekturen in der Lage, den Stil zu extrahieren. Daraus kann geschlussfolgert werden, dass möglicherweise sogar Netzwerkarchitekturen mit weniger lernbaren Parametern, als die hier vorgeschlagenen, in der Lage sein könnten, Stile aus Gemälden zu erlernen. Bei weiteren Experimenten wäre man unter Umständen in der Lage gewesen, noch performantere Netzwerkarchitekturen zu finden.

Die Auswahl der verwendeten Gemälde in dieser Arbeit geschah unter besonderer Berücksichtigung des Urheberschutzes. Ein kommerzieller Einsatz wäre nicht in jedem Fall möglich. Der Gebrauch von Style Transfer Methoden wirft besondere urheberrechtliche Bedenken auf. Urheberrechtlich geschützte Bilder können dazu verwendet werden, Stile zu extrahieren und auf neue Bilder zu übertragen. Die in Bezug auf Urheberrecht aufkommenden Fragen müssen für den produktiven Einsatz eines Software-Systems evaluiert werden.

\section{Ausblick}

Nachfolgend wird ein Ausblick auf Erweiterungen des Algorithmus gewährt. Es wird auf vorstellbare Funktionen und Einstellungen eingegangen.

\subsection{Verwendung anderer Layer-Kombinationen}

In dieser Arbeit wurden für die Berechnung des Style-Loss die Layer relu1\_2, relu2\_2, relu3\_3, relu4\_3 und für die Berechnung des Content-Loss der Layer relu3\_3 des \gls{vgg16}-Modells verwendet. Man kann ein anderes Loss-Network und andere Kombinationen von Layern für die Berechnung des Loss benutzen. Das hätte zur Folge, dass die generierten Stile sich unterscheiden würden. Im GitHub-Repository von Logan Engstrom  \cite{engstrom2016faststyletransfer} wurde dies bereits implementiert.

\subsection{Kombination aus mehreren Stilen}
\label{sec:combination_many_styles}

Vorstellbar ist eine Vermischung von mehreren Stilen. Hierzu müsste man das Style-Loss aus den Gram-Matrizen mehrerer Gemälde kombinieren. Im Paper \cite{stanfordStyleTransfer} wurde dies und andere Erweiterungen beschrieben.

\subsection{Superresolution}
\label{sec:superresolution}

Neben Style Transfer kann eine ähnliche Methodik für einen Super-Resolution-Algorithmus verwendet werden. Dieser wird ebenfalls im Paper von Johnson et al. \cite{DBLP:journals/corr/JohnsonAL16} beschrieben. Es muss eine Netzwerkarchitektur verwendet werden, die in der Lage ist, Bilder auf eine höhere Auflösung zu skalieren. Die verwendete Loss-Funktion wäre das bereits vorgestellte Perceptual-Loss jedoch ohne den Style-Loss-Anteil.

\subsection{Alternativen zum ResidualBlock}
\label{sec:alternatives_to_residual_block}

Hinsichtlich der Performanz können weitere Experimente mit kleineren Netzwerkarchitekturen durchgeführt werden. Außerdem kann der ResidualBlock durch eine andere Art von Block ersetzt werden. Die Paper \cite{DBLP:journals/corr/HowardZCKWWAA17} und \cite{DBLP:journals/corr/abs-1801-04381} behandeln sogenannte MobileNets, welche besonders auf die Verwendung von Geräten mit leistungsarmer Hardware abzielen. Vorstellbar wäre es, die verwendeten Blöcke anstelle des ResidualBlocks zu benutzen und damit weitere Experimente durchzuführen.

\subsection{Video Stylization}
\label{sec:video_stylization}

Im Paper \cite{DBLP:journals/corr/abs-1807-01197} wird beschrieben, wie Style Transfer für Videos realisiert werden kann. Dabei wird eine zusätzliche Loss-Funktion eingeführt, die ein Flickern zwischen den einzelnen Video-Frames verhindert.

\subsection{Ausführung im Webbrowser}
\label{sec:inference_in_browser}

Ein neu aufkommendes Feld ist die Realisierung von Deep Learning im Webbrowser. Tensorflow.js\footnote{\url{https://www.tensorflow.org/js}} ist ein Framework, dass Modelle direkt im Browser und somit auch direkt auf beispielsweise Mobiltelefonen oder anderen Geräten mit leistungsarmer Hardware ausführen kann. Ein weiteres Werkzeug ist ONNX.js\footnote{\url{https://github.com/microsoft/onnxjs}}. In PyTorch trainierte Modelle können in das ONNX-Format exportiert werden und mit ONNX.js direkt im Webbrowser ausgeführt werden. Zum Zeitpunkt der Erstellung dieser Arbeit befindet sich ONNX.js noch in einem frühen Entwicklungsstadium. Zukünftig ist ein Exportieren der in dieser Arbeit erstellten Modelle vorstellbar.